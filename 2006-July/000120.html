<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-core] Distributed Launcher
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-core/2006-July/index.html" >
   <LINK REL="made" HREF="mailto:plearn-core%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-core%5D%20Distributed%20Launcher&In-Reply-To=%3C44B3E85C.2070004%40apstat.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000119.html">
   <LINK REL="Next"  HREF="000121.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-core] Distributed Launcher</H1>
    <B>Pascal Vincent</B> 
    <A HREF="mailto:plearn-core%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-core%5D%20Distributed%20Launcher&In-Reply-To=%3C44B3E85C.2070004%40apstat.com%3E"
       TITLE="[Plearn-core] Distributed Launcher">pascal at apstat.com
       </A><BR>
    <I>Tue Jul 11 20:05:16 CEST 2006</I>
    <P><UL>
        <LI>Previous message: <A HREF="000119.html">[Plearn-core] Distributed Launcher
</A></li>
        <LI>Next message: <A HREF="000121.html">[Plearn-core] Distributed Launcher
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#120">[ date ]</a>
              <a href="thread.html#120">[ thread ]</a>
              <a href="subject.html#120">[ subject ]</a>
              <a href="author.html#120">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Pascal Lamblin wrote:
&gt;<i> On Mon, Jul 10, 2006, Pascal Vincent wrote:
</I>&gt;<i>   
</I>&gt;&gt;<i> It seems that we have a different focus here. You seam really focused
</I>&gt;&gt;<i> on a batch job queue of independent jobs,
</I>&gt;&gt;<i>     
</I>&gt;<i>
</I>&gt;<i> Yes, since that is what seems to be needed for pymake, pytest and
</I>&gt;<i> apdispatch/msdispatch...
</I>&gt;<i>   
</I>Indeed. However it's important for some of these tasks (ex: parallel 
compilation) to not append a job to a batch queue that might be executed 
in, say, 3 days... In that case it's better to compile the file locally. 
It seems we really want to use the computation ressources available now 
or very soon, or else would rather find another way. So it's not exactly 
a typical batch setting.

&gt;<i>   
</I>&gt;&gt;<i> while my focus is more on launching parallel processing jobs which may
</I>&gt;&gt;<i> need to communicate: so they have to run together, not one after the
</I>&gt;&gt;<i> other...
</I>&gt;&gt;<i>     
</I>&gt;<i>
</I>&gt;<i> OK, I didn't think about that. What would that system be used for?
</I>&gt;<i> Launching several plearn servers and communicating with them from a
</I>&gt;<i> central task manager?
</I>&gt;<i>   
</I>Yes that's the idea.
&gt;<i> Would unix pipes be enough for the communication of these processes ?
</I>&gt;<i>   
</I>Well, they would at least be enough to report back for ex. an IP adress 
and a port number of a socket to which to connect. Of course, this could 
always be worked around by having the plearn server write this stuff to 
some file, and the caller retrieve this info from file (?).

By the way, the issue of file-system access is another thing to consider 
in the launch system: do the different parallel ressources see the same 
file system for read/write or not. If not how do we handle the 
putting/retrieving of necessary files in the right locations. Have you 
already thought about this issue and come to some conclusions?

&gt;<i>   
</I>&gt;&gt;<i> Hence it's important to know how many I may expect to launch together
</I>&gt;&gt;<i> at the same time (the &quot;query&quot; operation), and to get some initial i/o
</I>&gt;&gt;<i> communication channel to them.
</I>&gt;&gt;<i>     
</I>&gt;<i>
</I>&gt;<i> I'm not sure you can do that on the mammouth (I really have to check the
</I>&gt;<i> documentation), or with condor (I don't know if it is possible to
</I>&gt;<i> specify that a group of jobs must be running at the same time on
</I>&gt;<i> different machines).
</I>&gt;<i>   
</I>I'd expect it's at least possible to launch some sort of parallel job 
(maybe based on MPI), otherwise these systems are seriously limiting the 
possible uses of a computation cluster.
&gt;<i>   
</I>&gt;&gt;<i> These is really a different focus, and maybe we should indeed consider
</I>&gt;&gt;<i> 2 different sub-systems, but both should be adressed somehow.
</I>&gt;&gt;<i>     
</I>&gt;<i>
</I>&gt;<i> Since I'm not sure I see what you really expect from that system, I
</I>&gt;<i> don't know how we can combine both.
</I>&gt;<i>
</I>&gt;<i> I would be in favor of putting the two functionalities into two
</I>&gt;<i> different systems, but we might take advantage of reusing some
</I>&gt;<i> components.
</I>&gt;<i>   
</I>Whatever works best, I trust your judgment.


Olivier Delalleau wrote:
&gt;&gt;<i> Some time ago Christian Hudon wrote a simple ssh-based launcher called 
</I>&gt;&gt;<i> cldispatch with a very simple semantic:
</I>&gt;&gt;<i> cldispatch mycommand myarg1 myarg2
</I>&gt;&gt;<i> launches mycommand with the given args on some available remote machine 
</I>&gt;&gt;<i> redirecting its stdin/stdout/stderr as if it had been launched locally 
</I>&gt;&gt;<i> (also does a cd in the current directory).
</I>&gt;&gt;<i> This, I feel is a very simple and basic operation that Dan's launcher 
</I>&gt;&gt;<i> should also allow (which does not mean it may not allow also more 
</I>&gt;&gt;<i> complex things).
</I>&gt;&gt;<i>     
</I>&gt;<i>
</I>&gt;<i> But it may not be possible on all clusters. As Pascal L. said, I don't
</I>&gt;<i> think you can do this on the Mammouth (the output probably needs to be
</I>&gt;<i> redirected to a file).
</I>&gt;<i>   
</I>&gt;<i> If you want communication between different processes, it seems to me
</I>&gt;<i> that using MPI would be the logical choice.
</I>&gt;<i>   
</I>Yes MPI is one way (it should be very easy to write a MPI based 
PStreamBuf for this), but if the communication is to happen through TCP 
links anyway, MPI appears to be just another unnecessary additional 
layer and dependency. But if MPI is the only way to go, then it should 
be properly installed and configured on all potential computation nodes.


-- 
Pascal Vincent
Directeur Technique, ApSTAT Technologies Inc.
Tel: (514) 343-9119  #219
<A HREF="http://www.apstat.com">http://www.apstat.com</A>


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000119.html">[Plearn-core] Distributed Launcher
</A></li>
	<LI>Next message: <A HREF="000121.html">[Plearn-core] Distributed Launcher
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#120">[ date ]</a>
              <a href="thread.html#120">[ thread ]</a>
              <a href="subject.html#120">[ subject ]</a>
              <a href="author.html#120">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-core">More information about the Plearn-core
mailing list</a><br>
</body></html>
